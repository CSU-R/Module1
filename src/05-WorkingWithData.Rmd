# Working with Data


```{block, type="caution"}
Portions of this chapter are still under construction. Sections in progress will start with a caution block like this one.
```

> The goal is to turn data into information, and information into insight.” – Carly Fiorina, former CEO of Hewlett-Packard

In the previous chapter, we've talked about the different types of data that R stores and the different structures that R stores data _in_.
We've mostly just made up numbers, character strings, and logical values for illustration.
In this chapter, we'll use R to do interesting things with _real data_.
This is by far the most popular use of the R programming language, and arguably the most fun!
You'll learn how to read data sets into R, do interesting things with them, and save your results.

## Quick Example 
Before diving into detail, let's do a quick example so you can begin to see what is possible with data in R.
As we mentioned in the last chapter, R includes some pre-packaged data sets, which you can access with the `data()` command.
One of the data sets is `Seatbelts`, which documents road casualties in Great Britain between 1969 and 1984.
Firstly, we need to convert `Seatbelts` to a data frame, because it starts out as a "Time-Series", which we haven't discussed.
```{r}
Seatbelts <- data.frame(as.matrix(Seatbelts), date=time(Seatbelts))   # convert Time Series to data frame
```
We've also added a month and year column 

look at the dimensions of the data set with the `dim` command:
```{r}
dim(Seatbelts)   # get the number of dimensions in the Seatbelts data frame
```
This shows that there are 192 rows (months), and 9 columns (variables measured each month).
We could also determine the number of rows and columns separately using the `nrow` and `ncol` functions.
To view the first few rows of the Seatbelts data frame, use the `head` command:

```{r}
head(Seatbelts)  # view first few rows of the Seatbelts dataset
```

This is a good way to learn which variables are being measured (columns) and see some example observations (rows) for each variable.
Because these data are included with R, more information about each variable can be found with:

```{r, eval=F}
?Seatbelts
```

Next, let's view a summary of each column with the summary function:

```{r}
summary(Seatbelts)
```

Since each column is numeric, R shows a five number summary (minimum, first quartile, median, third quartile, maximum) and mean for each column. 
We learn, for example, that the average number of drivers killed per month is 1670, and that the greatest price of petrol was £0.13 per litre!
Let's view a histogram of `DriversKilled`:

```{r, fig.cap="Histogram of Drivers Killed in Seatbelt data"}
hist(Seatbelts$DriversKilled, breaks=20)
```
We see that in some months, more than 150 drivers were killed!
We can calculate how many exactly like so:

```{r}
sum(Seatbelts$DriversKilled > 150)
```
To investigate the effect of the seat belt law, let's create a scatter plot Drivers killed against time:
```{r, fig.keep='all', fig.cap="UK Seatbelt deaths vs time"}
plot(Seatbelts$date, Seatbelts$DriversKilled)
```
By adding a `col` argument to the `plot` function, we can color the points based on whether the law was in effect:

```{r, fig.keep='all', fig.cap="UK Seatbelt deaths vs time, red = no seatbelt law, green = seatbelt law"}
plot(Seatbelts$date, Seatbelts$DriversKilled, col=(Seatbelts$law+2))
```

There do appear to be fewer deaths, but there is so much fluctuation in deaths each year that it's difficult to tell.

Let's change the x-axis to reflect month of the year instead of date:

```{r, fig.cap="UK Driver Deaths vs. Month"}
plot((Seatbelts$date %% 1) * 12 + 1, Seatbelts$DriversKilled, 
     xlab = "Month", col=Seatbelts$law + 2)
```
This plot shows that there is a clear seasonal effect in the number of deaths with higher deaths occurring in the Fall/Winter compared to Spring/Summer.
We can also see that within each month, the traffic deaths after enacting the Seatbelt law are among the lowest.

```{block, type="progress"}
Another data set included in R is `mtcars`. Following the example above, find the dimension of `mtcars` and have R print out a summary of each column, then create a scatter plot of fuel economy (`mpg`) to engine displacement.
What do you observe about the relationship between these two variables?
```

This concludes the quick example.
In the rest of this chapter, we'll talk in more detail about the different steps of working with data, and how to complete them using R!

```{block, type="reflect"}
People often use data in order to answer questions, but often times, learning about data can generate even _more_ questions than it answers.
Take a moment to think of a question that you have about the `Seatbelts` dataset. 
Do you think the question can be answered using the data alone?
If not, what other sources of data might be available which can help answer the question?
```

```{block, type='feedback'}
Any feedback for this section? Click [here](https://docs.google.com/forms/d/e/1FAIpQLSePQZ3lIaCIPo9J2owXImHZ_9wBEgTo21A0s-A1ty28u4yfvw/viewform?entry.1684471501=Quick%20Example)
``` 

## Reading / Writing Data

Of course, if we want work on data which is NOT included in R, then we have to _read_ that data into R in order to work with it.
That is, the data are normally somewhere on your computer's hard drive (or SSD), and you must run a command in R which _reads_ that data into your R environment. 


### Olympic Athletes Example

Let's look another example, this time with a data set of Olympic athletes. 
This is just a subset of the full dataset, to make it easier for you to work with.
Here's how we'll _read_ them into R:

```{r}
# Read the csv file into a data frame called athletes
athletes <- read.csv("data_raw/olympic_athletes.csv")

# print a summary of the data frame
summary(athletes)
```

```{block2, type="caution"}
The above command only works because the data set is in a particular location (the data folder), and is in a particular format (csv). 
In the sections that follow, we'll discuss how to address both of these issues.
```

### Locating your data set

R is capable of reading data from your computer, no matter where it is, as long as you "point" R to the correct location.
The location is usually specified with a _file path_, which is a character string that specifies the folder structure that holds your file.
By default, R starts "looking" from the current working directory, and the file path used was `data_raw/olympic_athletes.csv`.
This means that R will look inside the current working directory for a folder called `data_raw`, and if it exists, R will look inside `data_raw` for a file called `olympic_athletes.csv`.
In this class, you should be working within an rstudio project, which automatically sets the working directory.
If you created the folders as instructed earlier, then you should already have a `data_raw` folder in your project directory.

```{block2, type="progress"}
Download the olympic athletes data set from [this link](data_raw/olympic_athletes.csv) and save it in your data_raw folder.
In your progress check document, simply write: "Olympic Data Downloaded"
```

### Reading CSV files

A common way of storing data in a computer file is called CSV, which stands for _comma-separated values_.
These files are _plain text_, so you can open them in any text editor like Word, Notepad, or even Google Docs.
Just like a data frame, these files contain data in rows and columns, where on each line, the columns are _separated_ from each other with a comma (`,`), which is technically called a _delimiter_.
Programs like Excel, Google Sheets, and R can read these files and understand their row-column structure.
In R, the function to read CSV files (as you saw above) is `read.csv`.
In addition, if you call up the help file for read.csv using `?`, you'll see that there are other similar functions as well, including `read.table`, and `read.delim`.

```{block, type="bonus"}
In many object oriented languages, the "dot" (`.`) is a special symbol used to access an attribute or method of an object.
In R, however,  variable names and function names can contain a dot, and the dot has no special purpose. 
There are some exceptions, however, that relate to function overloading, and R formulas, but these are advanced topics that will not be discussed here.
```

These functions are actually all different variations of the same, generic, function called `read.table`.
The difference is that `read.csv`, `read.delim`, and the others make different assumptions about what delimiters are being used, and how decimal numbers are displayed (e.g. one-and-a-half may be written as `1.5`, or `1,5` depending on where you live).
We will discuss functions and arguments more in the next chapter, but for now, see the following table for when to use each function:

```{r, echo=F}
df <- data.frame(Function=c("read.table", "read.csv", "read.csv2", "read.delim", "read.delim2"), Delimiter=c("Must specify with sep=...", ",", ";", "\\t (tab)", "\\t (tab)"), Decimals=c(".", ".", ",", ".", ","))
knitr::kable(df) %>% kable_styling()
```

Any of these functions accepts the argument `header=FALSE`, which indicates that the first row of the file _does not_ contain column names.
Without this argument, R will assume the first row _does_ contain column names.
If our Olympic athletes data did not contain headers in the first row, we would use this:

```{r, eval=F}
athletes <- read.csv("data_raw/olympic_athletes.csv", header=FALSE)
```

###  Writing CSV files

R also has the capability to _write_ a data frame to a CSV file on your computer, that could then be read by Excel, Sheets, etc.
Let's suppose we wanted to save a version of the athletes data with only the `Sex` and `Age` columns.
We could use the `write.csv` function:

```{r}
# make a new data frame with only the Sex and Age columns
athletes2 <- athletes[,c("Sex", "Age")]

# save the new data frame as a CSV in the clean data folder
write.csv(athletes2, "data_clean/olympic_athletes_age_sex.csv")
```

Notice we created a new data frame by selecting only the desired columns.
We will talk more about different ways to select data when we discuss _indexing_.
Notice also that the write.csv function requires that we give it the name of the data frame being saved (`athletes2`), then the file path for the csv file that the data will be written to (`"data_clean/olympic_athletes_age_sex.csv"`).

```{block, type="caution"}
`write.csv` is an example of a function which takes _multiple arguments_, separating them with a comma (`,`). Usually, these arguments must be specified in order, but more will be said about this later.
```

```{block, type="progress"}
Create a version of the athletes data frame which contains the athletes' names and their sports.
Save the new data frame as a csv file in your data_clean folder with the file name "olympic_athletes_name_sport.csv".
Include the code in your progress check assignment.
```

```{block, type="caution"}
The `read` and `write` terminology may seem odd if you have not heard those terms before.
Your computer's hard drive (or SSD) will store data which will be remembered even after you turn off your computer.
The process of getting data from, and putting data on your hard drive (or SSD) is called _reading_ and _writing_.
```

```{block, type='feedback'}
Any feedback for this section? Click [here](https://docs.google.com/forms/d/e/1FAIpQLSePQZ3lIaCIPo9J2owXImHZ_9wBEgTo21A0s-A1ty28u4yfvw/viewform?entry.1684471501=Reading%20Writing%20Data)
```

## Summary Statistics

Reading and writing data is useful, but the power of R is _doing interesting things_ with the data!
Let's perform a few operations with the Olympic athletes data to demonstrate some important functions for data analysis. 
As we've seen, the `summary` function automatically performs some summary statistics on each column of a data frame.
Let's see how to produce these and other results manually.

### Quantitative Variables

To showcase the functions R provides to summarize quantitative variables, we'll look at the `Age` column of our data frame, which is stored as an integer vector in R.

```{block, type="reflect"}
What other R data types might be used to store quantitative data?
```

However, `Age` contains `NA` values, as we know from running the following function:

```{r}
sum(is.na(athletes$Age))   # count how many NA's are in the Age column
```

```{block2, type="reflect"}
Pause and think through what's happening in the above code. The `is.na` function returns a logical array which is true whenever the `Age` column is `NA`. So why does the `sum` function produce the number of `NA`'s?
```

As a cleaning step, we must first remove the `NA` values:
```{r}
age <- athletes$Age         # assign the Ages column to a variable
age <- age[!is.na(age)]   # extract only the elements which are not NA (more on this when we discuss advanced indexing)
```

```{block, type="bonus"}
This type of "data cleaning" is a very common first step when performing data analysis. You will get more opportunities to clean data later in the course.
```

Here are some functions R provides to summarize quantitative variables.
```{r}
age_min <- min(age)     # find the minimum age
age_med <- median(age)  # find the median age
age_max <- max(age)     # find the maximum age
age_mean <- mean(age)   # find the average age
age_sd <- sd(age)       # find the standard deviation of age
age_var <- var(age)     # find the variance of age
```

Let's put all these results in a named list.
In the following code, read the comments carefully to understand how the code is being organized onto multiple lines.

```{r}
# Create a list containing all the stats
age_stats <- list(  # R knows that this command continues until a closed parenthesis
  min = age_min,   
  median = age_med, 
  max = age_max,    
  mean = age_mean,  
  sd = age_sd,      
  var = age_var
)  # this could all go on one line, but it looks more organized this way.
age_stats
```

```{block2, type="progress"}
Using the Olympic Athletes data, create a list called `weight_stats` with the mean, median, and standard deviation of the `Weight` column. 
If you get `NA` values for the statistics, you should include the `na.rm=T` argument like so: `mean(weight, na.rm=T)`, to remove the `NA` values before computing the statistics.
```

Visualization will be discussed more later, but we'll show one plot now, to show how multiple summary statistics can be shown at the same time.

```{r, eval=F}
hist(age, breaks=50)
abline(v=age_mean, col="blue", lty=2, lwd=3)
abline(v=age_med, col="red", lty=2, lwd=3)
```
```{r, echo=F}
# not shown but knitted
{
hist(age, breaks=50)
abline(v=age_mean, col="blue", lty=2, lwd=3)
abline(v=age_med, col="red", lty=2, lwd=3)
}
```
It looks like the distribution of `Age` is _right skewed_, consistent with the fact that the mean is greater than the median.

### Categorical Variables

To showcase the functions R provides for categorical variables, we'll look, at the `Sport` column, which is stored as a character vector in R.

```{block, type="reflect"}
What other R data types might be used to store categorical data?
```

Are there any `NA` values in this column?

```{r}
sport <- athletes$Sport
sum(is.na(sport))
```

It turns out the answer is no, so there's no need to remove anything.
In a character vector like this, we expect there to be many duplicated values.
We can see a list of all the unique values with the following:

```{r}
unique(sport)
```

Using the numbers in brackets to the left as our guide, we can see that there are 57 unique values, but this can also be determined by running:

```{r}
length(unique(sport))
```
It would be nice to see how many times each entry occurs in the data set.
This is what the `table` function does:

```{r}
table(sport)
```

Let's save this table to a list as before:
```{r}
# assign summary statistics to variables
sport_n_unique <- length(unique(sport))
sport_counts <- table(sport)

# combine them into a list
sport_stats <- list(
  number_unique = sport_n_unique,
  counts = sport_counts
)
```

Again, a visualization may be useful here:

```{r, eval=F}
par(mar=c(5,15,4,2) + 0.1)  # command to make the labels fit
barplot(table(sport), horiz=T, las=2)   # bar plot
```
```{r, fig.height=20, echo=F, fig.asp=2}
# evaluated, but not shown (because RMarkdown needs brackets)
{
par(mar=c(5,15,4,2) + 0.1)  # command to make the labels fit
barplot(table(sport), horiz=T, las=2)   # bar plot
}
```

So we see that in our data set, athletics, swimming, and gymnastics have the most athletes (remember, each row is an athlete).

```{block2, type="progress"}
Using the Olympic athletes data, create a list called `season_stats` with the a table of counts for the `Season` variable.
```

```{block2, type="caution"}
It's always important to remember what the rows of your data set represent.
In the Olympic athletes example, one athlete may occupy multiple rows, if they competed in multiple olympic games.
This impacts how you should interpret the summary statistics computed above (mean, median, counts, etc.).
```
```{block2, type="reflect"}
Since an athlete may show up for multiple olympic games, what impact could this have on summary statistics for the `Height`, `Weight`, and `Sex` variables? Can you give an example of what might happen? What other variables may be impacted? What R code would you write to determine if an athlete occurred multiple times in the data frame?
```

### Saving an RData file

Finally, we may want to save these results for use _in R_ later.
First, we'll create a new list to put our two stats list _in_ (remember, we can have lists inside of other lists!).
```{r}
# Create list
athlete_stats <- list(
  age = age_stats,
  sport = sport_stats
)
```

```{block2, type="bonus"}
Remember that the `names` function retrieves the column names for a data frame? It also retrieves the names of a list (after all, a data frame is just a fancy list, right?)!
The following commands may be useful for remembering what the contents of our stats list:
  
  - `names(athlete_stats)`
  - `names(athlete_stats$age)`
  - `names(athlete_stats$sport)`

```

To save these results, we can use the `saveRDS` function:
```{r}
saveRDS(athlete_stats, "data_clean/athlete_stats.rds")
```

Later, we can use the following command to load the RDS file back into R:
```{r}
rm(athlete_stats)  # remove athlete stats to prove we are loading it from the hard drive

athlete_stats <- readRDS("data_clean/athlete_stats.rds")  # load the RDS file and name it athlete_stats

athlete_stats$age   # show that we have loaded the data by printing the age stats
```
```{block2, type="caution"}
Notice the file ends with _.rds_, indicating that this is a special RDS type which can only be read by R.
This is different from other data formats like CSV, which are plain text and can be read by other programs like Excel or Sheets.
RDS should only be used when you want to save work that you want to resume in R later.
If at all possible, you should prefer using plain text formats rather than RDS.
```

```{block2, type="bonus"}
RDS stands for _R Data Serialization_. This is R's version of object serialization, just like the io.Serializable interface in Java or the pickle module in Python.
As with other languages, R's serialization can only be used in R.
```

The RDS format works for any R Object, not just lists, so it can be used for vectors, matrices, factors, and even functions.

```{block, type='feedback'}
Any feedback for this section? Click [here](https://docs.google.com/forms/d/e/1FAIpQLSePQZ3lIaCIPo9J2owXImHZ_9wBEgTo21A0s-A1ty28u4yfvw/viewform?entry.1684471501=Summary%20Statistics)
``` 

## Data Formatting

Before we continue working with data, here are a few comments about data formatting.
Many data sets can be thought of as one or more _observations_ of one or more _variables_.
R functions work best when the data are formatted into rows and columns, so that each row is an observation, and each column is a variable.
Unfortunately, sometimes data do not follow this convention, or worse, it may not be clear what the observations or variables are.
Working with data often involves answering multiple questions, and different questions may require thinking of observations and variables differently.
In R, there are ways of changing the structure of data to suit your particular needs, but these are intermediate topics which will not be discussed here.

```{block, type="bonus"}
One concept related to data organization is called "Tidy Data", which you can read more about [here](https://vita.had.co.nz/papers/tidy-data.pdf). This focus on tidyness has led to the development of a set of R packages collectively called the "tidyverse", which has become very popular for R analysis. The tidyverse will not be covered in this class, but a later module will provide extensive experience with it.
```

### "Raw" data vs. "Clean" data.

Why is there a "data_raw" folder and a "data_clean" folder, and not just a "data" folder?
The idea is that the data_raw folder contains all of the _original_ data sets that you start with, before any cleaning or summarization take place, and any cleaned, modified, or created data sets that result from your data analysis should be stored in the "data_clean" folder (or possibly even a "results" folder).
This distinction ensures that the original data sets are preserved in their unedited state, just in case you need to start over from the beginning to answer a different question, and in order for others to easily replicate your work.
This is why the data in the folder should be thought of as _read only_. 
Sometimes people even modify the permissions of the raw data files on their computer to prevent anyone from accidentally deleting or overwriting the raw data.
The "clean" moniker comes from the fact that often times data sets need some "cleaning" such as removing duplicates, `NA` values, discarding irrelevant data, etc.
There are many other ways of organizing data, but the principle here is to separate the original data sets from any intermediate data sets. 

```{block2, type="reflect"}
Perhaps you've never thought about how data should be structured.
Consider an experiment which measures the temperatures of five guinea pigs is measured for each of four different days.
Think about organizing each row to be a guinea pig and each column to be a day. 
Can you think of an R function to compute the average tempareature on day 1?
How about the average temperature for guinea pig 3?
How do your answers change if the data are arranged with days as the rows and guinea pigs as columns?
Can you think of another way to organize the data?
```


```{block, type='feedback'}
Any feedback for this section? Click [here](https://docs.google.com/forms/d/e/1FAIpQLSePQZ3lIaCIPo9J2owXImHZ_9wBEgTo21A0s-A1ty28u4yfvw/viewform?entry.1684471501=Data%20Formatting)
``` 

## Indexing

Part of doing interesting things with data is being able to select just the data that you need for a particular circumstance. 
You've already seen how to get a particular element from a vector or matrix, or a specific component from a list, using _indices_.
A datum's _index_ is its position in the vector or list.
For example, to get the second element of a vector `A`, we use index 2 in square brackets: `A[2]`.
The process of selecting elements using their indices is called _indexing_, and R provides multiple ways of indexing vectors.
Below we'll cover some basic indexing and more advanced indexing for the different data structures in R.

### Vectors

Let's define a vector and access an element in the way you already know:

```{r}
# create an example vector
V <- c("A", "B", "C", "D", "E", "F", "G", "H", "I")

# access the 5th element
V[5]
```
```{block, type="caution"}
Unlike many other languages, R indices start with 1, not 0! so the first element is accessed as `A[1]`, etc.
```

Here are some other ways you can index as well.
You can access multiple indices at the same time using a numric vector of indices:

```{r}
V[c(1, 2, 5)]  # access elements 1, 2, and 5
```
If you need to access several indices in a row, you can use a colon (`:`):

```{r}
V[2:7]  # access elements 2 through 7
```
You can even combine these two methods:
```{r}
V[c(1:3, 6)]  # access elements 1, 2, 3, and 6
```
Note that the following are all equivalent ways to access the first three elements of `V`:

- `V[1:3]`
- `V[c(1,2,3)]`
- `V[c(1:3)]`
- `V[c(1:2,3)]`
- can you think of another example?

But the first way would probably be the most clear for someone else to understand.
All of these methods can work with _assignment_ as well:

```{r}
V[c(1, 7:9)] <- "X"  # change elements 1, 7, 8, and 9 to "X"
V
```

```{block, type="caution"}
Even though these examples use a character vector, this indexing works on vectors of any type.
```


### Matrices

To access an element of a matrix, we have to specify the row and the column.
Let's create a matrix from the `V` vector and access one of its elements:

```{r}
M <- matrix(V, 3, 3)  # create matrix M with data from vector V
M
```
```{r}
M[1,2]  # access the element in row 1, column 2
```

Recall that we can access an entire row or column by leaving the _other_ index blank:
```{r}
M[1,]  # access the entire first row
```
```{r}
M[,2]  # access the entire second column
```
But any of the indexing we just used for vectors can also be used on matrices

```{r}
M[1:2, c(2, 3)]  # access the elements in rows 1 and 2, columns 2 and 3.
```
Finally, there is one more way of indexing Matrices (for now), that provides only _one_ index:
```{r}
M[5]  # access the "5th" element of the matrix
```
If you give one index, then R will count down the first row, then the second, then the third, etc., until it reaches the index you specified.
Notice how this agrees with the 5th element of the matrix `V`, which was used to make our matrix!
And finally, as before, any of these indexing methods can be used to change an element's value:

```{r}
M[2, 1:3] <- "Hats"
M
```

### Lists

So far we've discussed three different ways of accessing elements in a list: 

```{r}
L <- list(A = "apple", b = "banana", c="cherry")

L[[1]]  # access using index number
```
```{r}
L[["b"]]  # access using component name
```

```{r}
L$c  # access using component name and dollar sign notation
```
And these are basically the only option.
Unfortunately, you _cannot_ use a vector of indices in order to access multiple list components at once:

```{r, error=TRUE}
L[[1:3]]  # this does not work
```
```{block2, type="bonus"}
What `L[[1:3]]` _actually_ does (as the error message might suggest), is access elements within a _nested_ list, but that is beyond the scope of this class.
```

```{block, type="progress"}
Create a vector containing the numbers 1 through 1000 in order (hint: try using 1:1000 on the right of the assignment operator).
Then, change elements 4, 196, and 501 through 556 to "brussels sprouts".
What happened to the other elements in the vector?
```

### Data Frames

Remember that data frames are just lists of vectors, so the same indexing rules of lists and vectors apply.
But remember that matrix indexing rules also apply!
Here are some examples with the Olympic athletes data. 

```{r}
athletes3 <- athletes[1:20,1:5]  # get the first 20 rows and first 5 columns, and assign it to athletes3
```

```{r}
athletes3$Name  # get the Name column
```

Remember that each column of a data frame is just a vector, so we can use list indexing to access the `Name` column, then _immediately_ use vector indexing to get only the indices that we want:

```{r}
athletes3$Name[1:3]  # get the first three elements of the Name column
```

```{block, type="caution"}
Notice how With lists, you _cannot_ access multiple components (which is what dataframe columns are) at the same time, but with matrices you _can_ access multiple columns at once. 
Since data frames can use matrix formatting, you _can_ select multiple columns at once, as the first example above showed.
```

You can also access 

```{r}
athletes3[,c("Name", "Sex")]  # Access Name and Sex columns
```

```{block, type="progress"}
Using the mtcars data frame (included in R), get the `mpg` for the cars in rows 15 through 20, and assign it to a vector.
Now find the average `mpg` of those cars.
```

```{block2, type="bonus"}
Think it's weird that data frames can be indexed like matrices? It gets weirder. When vectors have names, they can be indexed like lists! Try for yourself: create a vector `a <- c(1, 2, 3)` and set the names with `names(a) <- c("angus", "brillow", "chandelier")` , then see what happens if you type `a[["angus"]]`! Matrices can also be accessed using names as well.
```


### Advanced Indexing

There are _even more_ ways to select the data you need from your R data structures, let's look some more advanced techniques.

#### Logical Based Indexing

One _very_ useful method that R provides is to access elements of a vector using a different, logical vector of the same length. 
As the following example will show, R will give only the elements which are true in the logical vector:

```{r}
v <- c("alpha", "bravo", "charlie", "delta")  # the vector we want to access
i <- c(FALSE, TRUE, FALSE, TRUE)  # the logical vector we'll use to index.

# index v using i:
v[i]
```

Why is this so useful?
Remember that you can create logical vectors by comparing any type of vector to some value:
```{r}
v == "delta"
```
This means you can create a logical vector in order to extract only the elements of a vector which match some criterion.
For example, let's create a logical vector based on whether an Olympic athlete's sport was "Tug-Of-War".

```{r}
plays_tug_of_war <- athletes$Sport == "Tug-Of-War"  # create logical vector

sum(plays_tug_of_war)  # count how many TRUE's
```
Now let's use that logical vector to get the names of the athletes:
```{r}
athletes$Name[plays_tug_of_war]
```

```{block, type="progress"}
Using the Olympic athletes data, create a logical vector which is true when an athlete's sport is wrestling.
Then access the age of all wrestlers, and assign the ages to another vector.
Finally, compute the average age of the wrestlers vector (remember, there may be duplicate athlete names, so this average won't mean much; the emphasis is on indexing right now)
```

Logical vectors can also be used to subset a data frame based on some condition. 
That is, we take entire rows which meet a condition, rather than just a single variable.
For example:

```{r}
# Subset the athletes data frame to get only Summer athletes.
athletes_summer <- athletes[athletes$Season == "Summer",]
```

```{block2, type="caution"}
In the last example, we are creating the logical vector and immediately using it to index the rows.
Pause and think through what's happening in this example if it's not quite clear.
Also note the placement of the comma (`,`), which indicates that we're indexing rows, not columns, of the data frame.
```

You can specify multiple conditions using "and" (`&`) and "or" (`|`) like this:

```{r}
# create logical vector which is true for female gymnasts (female AND gymnast)
index <- (athletes$Sex == "F") & (athletes$Sport == "Gymnastics")

# select only female gymnasts
fem_gym <- athletes[index,]
```

```{r}
# create logical vector which is true if sport is basketball OR gymnastics
index <- (athletes$Sport == "Basketball") | (athletes$Sport == "Gymnastics")

# select athletes whos sport is basketball OR gymnastics. 
bb_gy <- athletes[index,]
```


```{block2, type="progress"}
Create a data frame called athletes_winter with only the rows whose `Season` is "Winter"
```

Another common use for Logical indexing is filling in missing values.
As part of data cleaning, you may decide to change `NA`'s to some other value. This is easy since we can create a logical vector which is `TRUE` when a value is `NA`.
We can do this with the `is.na` function:
```{r}
# For athletes with no medal, replace `NA` with "No Medal"
athletes$Medal[is.na(athletes$Medal)] <- "No Medal"
```

```{block, type="progress"}
Run the above code to replace NA values with "No Medal", and save the file in your data_clean folder as "athletes_clean.csv"
```

```{block, type="caution"}
This is not an endorsement of a particular approach to handling missing values. There are many situation dependent considerations that should be made in order to decide the best thing to do.
```


#### Negative Indexing

Sometimes it's easier to specify which columns or rows should be _excluded_ from indexing, rather than those that should be _included_.
To select every column except the first one, you can use a negative index:

```{r}
athletes[,-1]  # leave out the ID column
```

This also works with numeric vectors:

```{r}
athletes[-c(1:10),]  # access all but the first 10 rows.
```


#### Nested Indexing: [[1]][3]

In R, it's likely that at some point you will encounter nested data structures, such as vectors within lists (data frames!) and lists within lists.
This might make indexing more confusing at first, but a little practice will help you keep things organized in your mind.
Consider the following example:

```{r}
# create a vector and a matrix
V <- 1:16
M <- matrix(V, 4, 4)

# create a list which contains them:
L <- list(V, M)

# create a character vector
C <- c("I", "think", "therefore", "I", "am")

# create another list which will contain L and C:
L2 <- list(L, C)
```

With lists like this, it's easy to see code like `L2[[1]][[2]][2,3]` and get confused about what is happening.
It's best to break down the statement from left to right

```{r, eval=FALSE}
L2                 # the second list, L2
L2[[1]]            # the first component of L2, which is the first list, L
L2[[1]][[2]]       # the second element of L, which is the matrix M
L2[[1]][[2]][2,3]  # the second row and third column of M.
```

```{block, type="caution"}
We have discussed quite a few ways to index data, but rest assured there are more ways that we did not discuss! We won't address them now, to keep things simple! 
```

```{block, type='feedback'}
Any feedback for this section? Click [here](https://docs.google.com/forms/d/e/1FAIpQLSePQZ3lIaCIPo9J2owXImHZ_9wBEgTo21A0s-A1ty28u4yfvw/viewform?entry.1684471501=Indexing)
``` 

## Visualization

R is incredibly useful for creating visualizations and graphics which are easy to customize and automate, and entire university courses are dedicated to creating visualizations with R.
Here we can only introduce the basics of creating visualizations in R.

```{block2, type="caution"}
In this course, we focus on the visualizations in "base R", not the capabilities provided by outside sources.
This means we will not discuss the very popular `ggplot2` package, which has a very different way of constructing visualizations that could be confusing if included here.
```

R can make several different types of plots, and the type of plot will depend on what kind of data you are dealing with.
Below, we'll explore common types of plots for various types of data.

### One Quantitative Variable

One of the most popular ways of visualizing quantitative variables is with a histogram, where each bar represents the observations falling within a specific range.
The height of each bar reflects how many observations fall within that range.
In the Olympic athletes data, `Height` is a quantitative variable, so let's create a histogram using the `hist` function:

```{r, fig.height=4}
hist(athletes$Height)
```
This histogram shows that most heights are between roughly 160 and 190 inches, and the distribution looks _unimodal_.
Notice that R has decided how many bins (bars) to use, but this can be changed with the `breaks` option:

```{r, fig.height=4}
hist(athletes$Height, breaks=70)
```
R will "try" to create the number of bins equal to `breaks`, but sometimes won't make exactly that number.
Instead of just giving a single number breaks, you could _also_ give a vector of numbers, which specify the start and stop points of the bins:

```{r, fig.height=4}
hist(athletes$Height, breaks=c(120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230))
```
By default, R adds a title and axis labels to the plot, but for presentation purposes, it's probably a good idea to change them.
This can be done with the `main`, `xlab`, and `ylab` options:

```{r, fig.height=4}
hist(athletes$Height, breaks=60, main="Olympic Athlete Heights", xlab="Height (in)", ylab="")
```
These arguments work with many plot types in R.
In this example, we removed the y label by setting it to be an empty string.

```{block, type="progress"}
Using the clean athletes data, make a histogram of height for athletes whose sport is Basketball.
Hint: It might be easiest to create a new data frame with only basketball players first. 
Give it an appropriate title and axis labels.
```

```{block2, type="bonus"}
To see more options for the `hist` function, run `?hist`.
```

Another way to summarize a quantitative variable is with a boxplot, which shows a box whose boundaries are the first and third quartile. Inside the box, a line denotes the median, and the "whiskers" outside the box show which points are outliers (those outside the whiskers).

```{r, fig.width=3, fig.height=5}
boxplot(athletes$Height)
```
In this case, there are no default title or labels, but we can still add them:

```{r, fig.width=3, fig.height=5}
boxplot(athletes$Height, main="Olympic Athlete Height", ylab="Height (in)")
```
```{block2, type="caution"}
Hint: In RMarkdown, boxplots may look too wide by default. You can control the width of a figure by using the `fig.height` and `fig.width` commands in the chunk header like this:
  
` ```{r, fig.height=3, fit.width=5}`

These are the values used for the boxplot above.
```

The boxplot function also allows you to split up a quantitative variable using another variable, using the tilde (`~`).
Here are some examples:

```{r, fig.width=4, fig.height=5}
boxplot(athletes$Height ~ athletes$Sex)  # Make a boxplot of height, split by sex
```

```{r, eval=F}
par(mar=c(11,4,4,2) + 0.1)  # command to make the labels fit
boxplot(athletes$Height ~ athletes$Sport, las=2, xlab="")  # Make a boxplot of height, split by Sport
```
```{r, echo=F, fig.width=15, fig.height=8}
{
  par(mar=c(11,4,4,2) + 0.1)  # command to make the labels fit
  boxplot(athletes$Height ~ athletes$Sport, las=2, xlab="")  # Make a boxplot of height, split by Sport
}
```
Here we've added a few more bits to fit all the sport labels in: the `las` option rotates the labels, and the `par` function is used to increase the bottom margin below the graph. 

```{r, fig.width=10, fig.height=5}
boxplot(athletes$Height ~ athletes$Age)
```

```{block, type="caution"}
Different software will use different rules to determine how far out the "whiskers" go (and therefore which points are outliers). The default in R is 1.5 times the interquartile range, but this can be changed. When you view a boxplot, never assume what rule was used!
```

```{block, type="progress"}
Using the clean athletes data, make boxplots of Height for athletes whose Sport is "Cycling", separated by Medal.
Give it an appropriate title and axis labels.
Comment on the differences in Height between the different categories.
How many Cyclists have no height reported (that is, how many have `NA` for Height) and how many athletes have a height?
How should this affect your interpretation of the boxplots?
```


### Two Quantitative Variables

The most straightforward way to visualize two quantitative variables is with a scatter plot. 
In R, this is created with the `plot` function. 
Let's look at the relationship between height and weight in the Olympic athletes data, but only for a few sports.

```{r}
# select only some sports
gy_bb_wr <- athletes[athletes$Sport %in% c("Gymnastics", "Basketball", "Wrestling"),]

plot(gy_bb_wr$Height, gy_bb_wr$Weight)  # plot height vs weight
```
```{block, type="bonus"}
Above we saw another nice way to index: the `%in%` command. 
This returns a logical vector which is true for elements that are found in the search list.
```

There are a lot of points, so it may be useful to decrease the size of the circles using the `cex` option, which has a default value of 1:

```{r}
plot(gy_bb_wr$Height, gy_bb_wr$Weight, cex=0.4)  # Make circles smaller
```
Another option would be to change the type of marker, which can be selected using the `pch` option. 
We'll choose a smaller, solid circle, which is marker number 20:

```{r}
plot(gy_bb_wr$Height, gy_bb_wr$Weight, pch=20)  # try filled circles
```

We can also set the color using the `col` argument.
There are multiple ways to specify a color, but we'll use the `rgb` function, which allows us to specify how much red, green, and blue the color has.

```{r}
color <- rgb(0.5, 0, 1)
plot(gy_bb_wr$Height, gy_bb_wr$Weight, pch=20, col=color)  # change color
```

Lastly, we can also make the points less visible, so it's easier to see when they are overlapping one another.
This is done when defining the color, by giving a fourth value called the _alpha_, which represents how visible a point is.
An alpha value of 0 is invisible, and a value of 1 is fully visible.

```{r}
color <- rgb(0.5, 0, 1, 0.1)  # set the alpha level low, so points are transparent
plot(gy_bb_wr$Height, gy_bb_wr$Weight, pch=20, col=color)  # make points partially transparent
```
We can also color by sport, by converting the Sport column to a factor, then giving that as the color argument:

```{r}
colors <- as.factor(gy_bb_wr$Sport)
plot(gy_bb_wr$Height, gy_bb_wr$Weight, pch=20, col=colors)  # color by sport
```
```{block, type="caution"}
We convert Sport to a factor because the `col` option in plot is expecting either a single color (as in the first example) or a vector of numbers indicating which color should be used for each point (remember, factors are represented as numbers).
The numbers tell R which color in its palette it should use (for the default palette, 1=black, 2=reddish, 3=greenish, etc.),
so factor level 1 (Basketball) is colored black, level 2 (Gymnastics) is colored reddish, and level 3 (Wrestling) is colored greenish.
```

The default colors in R are sometimes not very appealing, so we can define our own color palette:

```{r}
palette(c(rgb(1,0,0,0.1), rgb(0,1,0,0.1), rgb(0,0,1,0.1)))   # create color palette
plot(gy_bb_wr$Height, gy_bb_wr$Weight, pch=20, col=colors)
```

In some cases, it might be appropriate to use lines instead of points.
This can be done by setting the `type` option to "l":

```{r, fig.height=3}
x <- (1:10)/10 * 2*pi
y <- sin(x)
plot(x, y, type="l")
```

You can use points and lines at the same time using "b":

```{r, fig.height=3}
plot(x, y, type="b")
```

Another option for plotting two quantitative variables, especially when there are many overlapping points, is the smooth scatter:

```{r}
smoothScatter(gy_bb_wr$Height, gy_bb_wr$Weight)
```

```{block, type="progress"}
Create a scatter plot of athlete height (y axis) vs. year (x axis) for athletes with Sport "Weightlifting", and color the points by Sex.
Create an appropriate title and axis titles.
What was the first year to allow Female Weightlifters?
```

### One Categorical Variables

One useful way to visualize categorical variables is bar plots.
Before creating a barplot, we need to create a summary table of the variable of interest:

```{r}
sport_tab <- table(gy_bb_wr$Sport)
barplot(sport_tab, col=rgb(0.2, 0.2, 1))
```

```{block, type="progress"}
Create a barplot for the Season variable, with an appropriate title and axis labels.
Which Season has more rows in the data frame??
```


### Two Categorical Variables

With two categorical variables, you can create a mosaicplot, where the size of each region is relative to the number of observations in that group.

```{r}
mosaicplot(gy_bb_wr$Sport ~ gy_bb_wr$Sex, col=c("blue", "orange"), main="Athlete Sex by Sport", xlab="Sport", ylab="Sex")
```

### Multiple plots

One nice feature of R's plotting capability is that you can plot multiple things at the same time.
One way to do this is to create a plot and then add another plot _on top_ of it, using either the `points` or `lines` function.
`points` will add a scatter plot using lines, and `lines` will add a scatter plot using a line.
Normally, a plotting function like `plot` or `hist` will create a new plot _figure_, erasing what may have been plotted before.
But with the `points` and `lines` functions, R just adds to the existing figure.
Here's an example of each:

```{r}
# create some data to plot
x <- (1:100)/100
y1 <- x
y2 <- sin(3/x)*x
```

```{r, eval=F}
plot(x, y2,)  # plot x against y2
points(x, y1, col="blue")  # add points of x against y1 (on same figure)
lines(x, -y1, col="red")  # add lines of x against -y1 (on same figure)
```
```{r, echo=F}
{
  plot(x, y2,)
  points(x, y1, col="blue")
  lines(x, -y1, col="red")
}
```


### Other types of plots

The following plots that are less common, but may be useful for you, and this is an opportunity to show some other capabilities of R!

#### Scatterplot Matrix

Given several quantitative variables, there are many different possible scatterplots you could make. 
The `pairs` function takes in a matrix or data frame and creates a matrix of all possible scatter plots.
Here's an example using the `iris` data set which is included in R:
```{r}
pairs(iris, pch=20)
```
To know the x axis for one of these plots, look up/down to the diagonal, which will tell you the variable on the x axis.
To know the y axis for one of these plots, look left/right to the diagonal, which will tell you the variable on the y axis.

#### Surfaces

If you need to plot a surface, there are a few options for visualization.
The first is `contour`, which shows level curves of the surface in a 2d plane:

```{r}
# Make a surface using the rep function
n <- 100
x <- rep(1:n, n)/n*2*pi
y <- rep(1:n, each=n)/n*2*pi
z <- matrix(sin(x) + cos(y), n, n)

contour(z, nlevels=20)
```

The second option is `parsp`, which gives a 3d perspective of the surface:

```{r, fig.height=8}
persp(z, theta=45, phi=30, shade=0.5)
```

### Saving Images

Creating visualizations in R wouldn't be very useful if there were no way to save them onto your hard drive (or ssd).
Thankfully, R provides various ways of doing this, depending on where the plot "lives". 
We'll talk through each of these below.

#### RCode

The most universal way to save plots is to use R code itself! This will work anywhere that R code can be run, whether that's the RStudio console, an R script, or an RMarkdown document. 
All you have to do is type a few simple commands.
The idea is, that normally R "sends" a plot to the plotting window (in the lower right of RStudio), or to the output of a code chunk (if you're using RMarkdown), but to save the file, you just have to change where R is sending the plot. 
For example, if you add put the `png` function before a plotting command, then instead of sending the plot to wherever it normally does, R will send the plot into the png file you specify. 
Here's an example:

```{r}
png("output/test_plot.png")  # start "sending" plots to the png file called "test_plot.png"
plot(y1, y2)          # this plot will go to "test_plot.png"
dev.off()             # Stop sending plots to "test_plot.png"
```
After you're done sending plots to a file, use the command `dev.off()` to reset where R is sending the plots

```{block2, type="bonus"}
R graphics works with objects called "graphics devices". 
The `png` function creates a new graphics device which is a file on your computer. 
The `dev.off()` shuts down the current graphics device, so no more plots are sent to the file. 
You can check out other `dev.` functions by running `?dev.off().
```

There are other commands like `png` as well, including `bmp` for bitmap images, and `jpeg` for jpeg images.
When you're sending a plot to a file, it will _not_ display in the plot window.

#### RStudio Plot Window

If you run code to generate a plot from the console or an R script, then the plot will show up in the RStudio plot window.
To save a figure displayed in the plot window, use the "Explort" button in the plot window menu.

#### RMarkdown

If you're plotting inside of an RMarkdown document, then plots will be shown inside your document.
One way to get them "out of RStudio" is simply to knit the document. 
But if you want the plot by itself, then right click on the plot and select "Save image as".

```{block, type="progress"}
Choose a plot that you previously created, and write code to save the plot to a png file in the "output" directory of your RStudio project.
Choose an appropriate filename for the file.
```


### Plotting Wrap Up

These examples of plotting are only scratching the surface.
There are many more things possible with base R graphics, not to mention the numerous other capabilities provided by community developed Packages.
Before ending this section, we'll leave you with an example from the `ggplot2` package, just to give you a taste of what's possible.

```{r, fig.height=5, fig.width=10}
library(ggplot2)

ggplot(gy_bb_wr, aes(Height, Weight, color=Sex)) +
  geom_point(alpha=0.2) + 
  theme_bw() + 
  labs(title="Athlete Height vs. Weight") + 
  facet_grid(Sex~Sport)

```


```{block, type='feedback'}
Any feedback for this section? Click [here](https://docs.google.com/forms/d/e/1FAIpQLSePQZ3lIaCIPo9J2owXImHZ_9wBEgTo21A0s-A1ty28u4yfvw/viewform?entry.1684471501=Basic%20Plotting)
``` 

## Vignettes

In this section, you'll gain more experience working with data by following along with some more data analysis examples.

### Flood analysis example

In this example we will learn how to analyze flood data to better understand
the history of flooding in the last ten years in the Cache La Poudre river 
which runs through Fort Collins. This vignette will help you learn three key ideas:

1) Data can be read into R directly from online data services using `packages`
which you will learn about more later in this book. 

2) We can use this 'live' data to understand both past and present river conditions
in the river.

3) We can use R to look at changes over time in river flow and water height.

#### Map

The river monitoring location for the Cache La Poudre River is right at Lincoln
Bridge near Odell Brewing. 

<iframe src="https://www.google.com/maps/embed?pb=!1m14!1m12!1m3!1d4284.611594695134!2d-105.07007728632453!3d40.592864378048056!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!5e0!3m2!1sen!2sus!4v1595604291467!5m2!1sen!2sus" width="600" height="450" frameborder="0" style="border:0;" allowfullscreen="" aria-hidden="false" tabindex="0"></iframe>

#### Installing and using packages

In order to download river flow and height data we will first need to load a 
package called `dataRetrieval` this is a package run by the United States 
Geological Survey (USGS) and it provides access to data from over 8000 
river monitoring
stations in the United States and millions of water quantity and quality 
records. You can learn more about the data from the USGS [here](https://waterdata.usgs.gov/nwis). To use packages we first have 
to install them using the command `install.packages` and then load them
using the command `library`. 

```{r, }
## Install the package if it's not already installed by uncommenting the line 
#below

#install.packages('dataRetrieval')

#load the package
library(dataRetrieval)

```

#### Downloading the data

Once we have loaded the package we can use
the special functions that it brings to the table. In this case `dataRetrival` 
provides a function called `readNWISdv` which can download daily data 
(or daily values, hence readNWIS*dv*) for specific
monitoring locations. But how do we use this function? 
Try `?readNWISdv` to get more details.
So the `readNWISdv` command requires a few key arguments. First
`siteNumbers`, these are simply the site identifiers that the USGS uses 
to track different monitoring stations and in our case that number for the 
Cache La Poudre is `06752260`, which you can find [here](https://waterdata.usgs.gov/co/nwis/uv?site_no=06752260).
The second argument is the `parameterCd` which
is a cryptic code that indicates what kind of data you want to download. In 
this case we want to download river flow data. River 
flow tells us how much water is moving past a given point over and is correlated
with the height of the river water. This code is `00060` for discharge which means
river flow. 
Lastly we need to tell the `readNWISdv` command the time period for which we want
data which is `startDate` which we will set to 2010,
and `endDate` which we will set to the current day using the command 
`Sys.Date()`. These arguments should be in the 
YYYY-MM-DD format. With all this knowledge of how the command works, we can
finally download some data, directly into R!

```{r}

poudre <- readNWISdv(siteNumbers = '06752260',
                     parameterCd = c('00060'),
                     startDate = '2010-10-01',
                     endDate = Sys.Date())
```


#### Explore the data structure


Now that we have our dataframe called `poudre`, we can explore the properties
of this data frame using commands we have already learn. First let's 
see what the structure of the data is using the `head` command, which 
will print the first 6 rows of data. 

```{r}
head(poudre)
```

It looks like we have a dataframe that is 5 columns wide with columns `agency_cd` which is just the USGS, `site_no` which is just the site id we already told it. Since
we only asked for data for one site, we don't really need this column. A `Date`
column which tells us... the date! There are two more columns that are kind of weird which
are labeled `X_00060_00003` which is the column that actually has values of 
river flow in Cubic Feet Per Second (cfs), or the amount of water that is flowing
by a location per second in Cubic Feet volume units (1 cubic foot ~ 7.5 gallons).
Finally `X_00060_00003_cd` tells us something about the quality of the data. For now
we will ignore this final column, but if you were doing an analysis of this data
for a project, you would want to investigate what codes are acceptable for 
high quality analyses. To make working with this data a little easier let's
rename and remove some of our columns in a new, simpler data.frame. 

```{r}
#Remove the first two columns
pq <- poudre[,-c(1,2,5)]

#Rename the remaining columns
names(pq) <- c('Date','q_cfs')

```

#### Explore the data.

Now that we have cleaned up our data.frame a little, let's explore the data.
First we can use a summary command to just quickly look at the variables we have.

```{r}
summary(pq)
```

It looks like we have data from 2010 to `r Sys.Date()` and a range in river
flow (q_cfs) from 2.6 cfs all the way up to 7150 cfs. If you're a hydrologist,
hopefully these flow numbers look right, but another way to check to make sure
is to simply plot the data as we do below. 

```{r}
plot(pq$q_cfs ~ pq$Date, type = 'l', ylab = 'River Flow (cfs)', 
     xlab = 'Date',col = 'blue3')

```

```{block, type = 'reflect'}
The above plot is called a "hydrograph" or a plot of how river flow has changed
over time. In the Cache La Poudre, what might explain the peaks and valleys of 
the data? What controls river flow in Colorado rivers. 

```

#### Analyze the data

Now that we plotted the data we can see some interesting patterns that we
might want to explore. For example how has the average flow changed in the last
ten years. To analyze this we need to use the concept of a `Water Year`. Simply
put, a water year is a way to analyze yearly variation in flow, which doesn't 
map well to a calendar year. Water years in the USA are typically from October 1
to September 30th. Luckily for us, the `dataRetrieval` package has a function
that calculates water year for us. It's simply called `addWaterYear`

```{r}
pq_wy <- addWaterYear(pq)

```


To look at variation per year we can use the function called `tapply` which can take the mean, max or any summary
function of groups of data (more on this in the next chapter, but you can type `?tapply` for more info).
In this case we want to look at the mean river flow for each water year.
Now to use tapply we use the following code


```{r}

annual <- tapply(pq_wy$q_cfs,pq_wy$waterYear, mean)

```

Now let's plot the data, where the values (y) are the annual average flow and the years (x) are the names of the annual vector from the `tapply` function. 

```{r}
plot(names(annual),(annual))
```
```{block, type = 'reflect'}

Has annual mean river declined over the past ten years?
What about the last 6? 


```



```{block, type='feedback'}
Any feedback for this section? Click [here](https://docs.google.com/forms/d/e/1FAIpQLSePQZ3lIaCIPo9J2owXImHZ_9wBEgTo21A0s-A1ty28u4yfvw/viewform?entry.1684471501=Vignettes)
``` 
